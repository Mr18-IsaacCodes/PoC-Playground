{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ffc915-61af-4732-8e12-ecabc9d73d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acf18555-7077-4d9c-b6db-62432b84c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# from pyspark.sql.functions import col, window, explode , from_json , count ,approx_count_distinct,to_timestamp\n",
    "from pyspark.sql.functions import *\n",
    "# from pyspark.sql.types import StructType, StructField, StringType, IntegerType,TimestampType\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04952990-dadc-4e43-9d84-ff592ac62731",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaClickstream\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2\") \\\n",
    "    .config(\"spark.hadoop.fs.file.impl\", \"org.apache.hadoop.fs.LocalFileSystem\") \\\n",
    "    .config(\"spark.hadoop.io.native.lib\", \"False\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45660db3-78ef-417b-9bff-53d688129871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "426d6318-55f0-4258-ac07-aa4eaac77934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa78cd2a-13ab-4f00-b96a-bab25f9ee676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for the incoming JSON data\n",
    "schema = StructType([\n",
    "    StructField(\"user_id\", IntegerType(), True),\n",
    "    StructField(\"timestamp\", TimestampType(), True),  # Changed to TimestampType\n",
    "    StructField(\"event_type\", StringType(), True),\n",
    "    StructField(\"product_id\", IntegerType(), True),\n",
    "    StructField(\"session_id\", StringType(), True),\n",
    "    StructField(\"user_name\", StringType(), True),  # New field for user name\n",
    "    StructField(\"user_email\", StringType(), True),  # New field for user email\n",
    "    StructField(\"user_location\", StringType(), True)  # New field for user location\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e489f94a-c937-4f7d-8cc5-d8415d07446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the stream from Kafka\n",
    "kafka_stream_df = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"127.0.0.1:9092\") \\\n",
    "    .option(\"subscribe\", \"realtimedashboard\") \\\n",
    "    .option('startingOffsets', 'earliest') \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "896d6637-0785-4cb4-a4ea-e73e23db5e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the message value and parse JSON into structured data\n",
    "clickstream_df = kafka_stream_df.selectExpr(\"CAST(value AS STRING)\") \\\n",
    "    .select(from_json(col(\"value\"), schema).alias(\"data\")) \\\n",
    "    .select(\"data.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58a4a4e1-54b8-474b-9125-567d1b931657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out only \"click\" and \"purchase\" events\n",
    "filtered_df = clickstream_df.filter(clickstream_df.event_type.isin('click', 'purchase'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c068219e-9884-4db4-8950-96c9cd1579b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_df = filtered_df.withColumn(\"timestamp\", to_timestamp(\"timestamp\", \"yyyy-MM-dd'T'HH:mm:ss.SSSSSS\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77fb7481-69cc-468b-a8b4-f247d8be3513",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_csv_path = r\"C:/Users/hp/Kafka poc/Real_Time_Streaming/dim_products.csv\"\n",
    "\n",
    "product_df = spark.read.option(\"header\", \"true\").csv(product_csv_path, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2977509b-d39c-4101-8399-d6b1e08d91ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------+--------------------+--------------------+------+-----+--------+------------+--------------------+--------------+--------+----------+----------+\n",
      "|product_id|  product_name|category|               brand|       supplier_name| price|color|    size|release_date|         description|stock_quantity|discount|created_at|updated_at|\n",
      "+----------+--------------+--------+--------------------+--------------------+------+-----+--------+------------+--------------------+--------------+--------+----------+----------+\n",
      "|      3778|Life President|  Beauty|        Hall-Mccarty|     Johnson-Johnson|869.03| Blue|  Medium|  2024-01-18|Follow suggest it...|           345|    0.43|2025-02-07|2025-02-03|\n",
      "|      9871|   Bring Woman|    Home|         Baldwin PLC|       Rodriguez Inc|697.09|Green|One size|  2021-11-05|Alone left throug...|           318|    0.42|2025-02-08|2025-02-18|\n",
      "|      3441|     Door Side|    Home|Taylor, Gutierrez...|           Singh LLC| 495.1|White|One size|  2024-03-15|Test sit opportun...|            37|     0.4|2025-02-24|2025-01-24|\n",
      "|      2457|  Standard Son|    Home|       Wood and Sons|         Flynn-Young|538.29|White| X-Large|  2020-02-15|Area painting beh...|           131|    0.39|2025-01-06|2025-01-25|\n",
      "|      5271|    Hard Spend|    Toys|      Parsons-Harvey|Richmond, Pope an...|526.68|Black|  Medium|  2022-06-22|Left rise mind sc...|           114|    0.04|2025-01-26|2025-03-03|\n",
      "+----------+--------------+--------+--------------------+--------------------+------+-----+--------+------------+--------------------+--------------+--------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_df.show(5,truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb5b9585-25c8-4afd-8d21-694806e5d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the clickstream data with the product information\n",
    "enriched_df = parsed_df.join(product_df, \"product_id\", \"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2875d2-77f0-48d8-a7f8-6782550c76bc",
   "metadata": {},
   "source": [
    "Total Revenue by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fe40443-96ae-4069-9f20-762052d24bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate revenue for each transaction (price * (1 - discount))\n",
    "enriched_df = enriched_df.withColumn(\"revenue\", enriched_df[\"price\"] * (1 - enriched_df[\"discount\"]))\n",
    "\n",
    "enriched_df_with_watermark = enriched_df.withWatermark(\"timestamp\", \"5 seconds\")\n",
    "\n",
    "# Total revenue by category\n",
    "total_revenue_by_category = enriched_df_with_watermark.withColumn(\"window\", window(\"timestamp\", \"5 seconds\")).groupBy(\"category\",\"window\").agg(sum(\"revenue\").alias(\"total_revenue\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e472e7b-4c8b-4984-a83b-0bb2dfcc2367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch_df, batch_id):\n",
    "    print(f\"Processing batch {batch_id}\")\n",
    "    batch_count = batch_df.count()  # Check how many rows are in this batch\n",
    "    print(f\"Number of rows in batch {batch_id}: {batch_count}\")\n",
    "    batch_df.show(5, truncate=False)  # Display a few rows of the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04b121c3-40ee-4b32-ac64-38ac4f3de5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 0\n",
      "Number of rows in batch 0: 488\n",
      "+--------+------------------------------------------+-------------+\n",
      "|category|window                                    |total_revenue|\n",
      "+--------+------------------------------------------+-------------+\n",
      "|NULL    |{2025-03-04 18:22:10, 2025-03-04 18:22:15}|NULL         |\n",
      "|NULL    |{2025-03-04 18:16:25, 2025-03-04 18:16:30}|NULL         |\n",
      "|NULL    |{2025-03-04 18:46:00, 2025-03-04 18:46:05}|NULL         |\n",
      "|NULL    |{2025-03-04 18:39:35, 2025-03-04 18:39:40}|NULL         |\n",
      "|NULL    |{2025-03-04 18:26:50, 2025-03-04 18:26:55}|NULL         |\n",
      "+--------+------------------------------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing batch 1\n",
      "Number of rows in batch 1: 495\n",
      "+--------+------------------------------------------+-------------+\n",
      "|category|window                                    |total_revenue|\n",
      "+--------+------------------------------------------+-------------+\n",
      "|NULL    |{2025-03-04 18:22:10, 2025-03-04 18:22:15}|NULL         |\n",
      "|NULL    |{2025-03-04 18:16:25, 2025-03-04 18:16:30}|NULL         |\n",
      "|NULL    |{2025-03-04 18:46:00, 2025-03-04 18:46:05}|NULL         |\n",
      "|NULL    |{2025-03-04 18:39:35, 2025-03-04 18:39:40}|NULL         |\n",
      "|NULL    |{2025-03-04 18:26:50, 2025-03-04 18:26:55}|NULL         |\n",
      "+--------+------------------------------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing batch 2\n",
      "Number of rows in batch 2: 500\n",
      "+--------+------------------------------------------+-------------+\n",
      "|category|window                                    |total_revenue|\n",
      "+--------+------------------------------------------+-------------+\n",
      "|NULL    |{2025-03-04 18:22:10, 2025-03-04 18:22:15}|NULL         |\n",
      "|NULL    |{2025-03-04 18:16:25, 2025-03-04 18:16:30}|NULL         |\n",
      "|NULL    |{2025-03-04 18:46:00, 2025-03-04 18:46:05}|NULL         |\n",
      "|NULL    |{2025-03-04 18:39:35, 2025-03-04 18:39:40}|NULL         |\n",
      "|NULL    |{2025-03-04 18:26:50, 2025-03-04 18:26:55}|NULL         |\n",
      "+--------+------------------------------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing batch 3\n",
      "Number of rows in batch 3: 506\n",
      "+--------+------------------------------------------+-------------+\n",
      "|category|window                                    |total_revenue|\n",
      "+--------+------------------------------------------+-------------+\n",
      "|NULL    |{2025-03-04 18:22:10, 2025-03-04 18:22:15}|NULL         |\n",
      "|NULL    |{2025-03-04 18:16:25, 2025-03-04 18:16:30}|NULL         |\n",
      "|NULL    |{2025-03-04 18:46:00, 2025-03-04 18:46:05}|NULL         |\n",
      "|NULL    |{2025-03-04 18:39:35, 2025-03-04 18:39:40}|NULL         |\n",
      "|NULL    |{2025-03-04 18:26:50, 2025-03-04 18:26:55}|NULL         |\n",
      "+--------+------------------------------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing batch 4\n",
      "Number of rows in batch 4: 514\n",
      "+--------+------------------------------------------+-------------+\n",
      "|category|window                                    |total_revenue|\n",
      "+--------+------------------------------------------+-------------+\n",
      "|NULL    |{2025-03-04 18:22:10, 2025-03-04 18:22:15}|NULL         |\n",
      "|NULL    |{2025-03-04 18:16:25, 2025-03-04 18:16:30}|NULL         |\n",
      "|NULL    |{2025-03-04 18:46:00, 2025-03-04 18:46:05}|NULL         |\n",
      "|NULL    |{2025-03-04 18:39:35, 2025-03-04 18:39:40}|NULL         |\n",
      "|NULL    |{2025-03-04 18:26:50, 2025-03-04 18:26:55}|NULL         |\n",
      "+--------+------------------------------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing batch 5\n",
      "Number of rows in batch 5: 520\n",
      "+--------+------------------------------------------+-------------+\n",
      "|category|window                                    |total_revenue|\n",
      "+--------+------------------------------------------+-------------+\n",
      "|NULL    |{2025-03-04 18:22:10, 2025-03-04 18:22:15}|NULL         |\n",
      "|NULL    |{2025-03-04 18:16:25, 2025-03-04 18:16:30}|NULL         |\n",
      "|NULL    |{2025-03-04 18:46:00, 2025-03-04 18:46:05}|NULL         |\n",
      "|NULL    |{2025-03-04 18:39:35, 2025-03-04 18:39:40}|NULL         |\n",
      "|NULL    |{2025-03-04 18:26:50, 2025-03-04 18:26:55}|NULL         |\n",
      "+--------+------------------------------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing batch 6\n",
      "Processing batch 0\n",
      "+----------+------------+--------------+\n",
      "|product_id|product_name|purchase_count|\n",
      "+----------+------------+--------------+\n",
      "|5209      |Tv School   |2             |\n",
      "|6673      |NULL        |2             |\n",
      "|1041      |Hear Week   |1             |\n",
      "|6336      |NULL        |1             |\n",
      "|4519      |NULL        |1             |\n",
      "+----------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing batch 1\n",
      "+----------+------------+--------------+\n",
      "|product_id|product_name|purchase_count|\n",
      "+----------+------------+--------------+\n",
      "|5209      |Tv School   |2             |\n",
      "|6673      |NULL        |2             |\n",
      "|1041      |Hear Week   |1             |\n",
      "|6336      |NULL        |1             |\n",
      "|4519      |NULL        |1             |\n",
      "+----------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = total_revenue_by_category_with_watermark \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .trigger(processingTime=\"5 seconds\") \\\n",
    "    .foreachBatch(process_batch) \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd5ee4e0-2cdc-449c-b71a-5a03a5debc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fdd051-dc96-4bb9-91fa-33f42495060f",
   "metadata": {},
   "source": [
    "Top Products by Purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd5058ec-eca5-458d-b7e6-7bb8df0fe956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of purchases for each product\n",
    "top_products = enriched_df.filter(enriched_df[\"event_type\"] == \"purchase\") \\\n",
    "    .groupBy(\"product_id\", \"product_name\") \\\n",
    "    .agg(count(\"event_type\").alias(\"purchase_count\")) \\\n",
    "    .orderBy(desc(\"purchase_count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "decdc71f-d864-49e3-829d-fdaa88bf47e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch_df, batch_id):\n",
    "    print(f\"Processing batch {batch_id}\")\n",
    "    batch_df.show(5, truncate=False)\n",
    "\n",
    "query = top_products \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .trigger(processingTime=\"5 seconds\") \\\n",
    "    .foreachBatch(process_batch) \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea7a39ec-5c96-4cd4-a2e4-1e1ecf999a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4980b95a-8a0b-4e84-894e-2399255ab07b",
   "metadata": {},
   "source": [
    "Average Discount per Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8365eef6-e5f5-41e8-874f-7af9037e9dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_discount_by_category = enriched_df.groupBy(\"category\").agg(avg(\"discount\").alias(\"avg_discount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54bc8e9b-d97f-4243-adda-c6718e0b7b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 0\n",
      "+-----------+-------------------+\n",
      "|category   |avg_discount       |\n",
      "+-----------+-------------------+\n",
      "|Home       |0.2555555555555556 |\n",
      "|Sports     |0.21875            |\n",
      "|Electronics|0.24285714285714285|\n",
      "|Clothing   |0.24400000000000005|\n",
      "|Beauty     |0.2285             |\n",
      "+-----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing batch 1\n",
      "+-----------+-------------------+\n",
      "|category   |avg_discount       |\n",
      "+-----------+-------------------+\n",
      "|Home       |0.2555555555555556 |\n",
      "|Sports     |0.21875            |\n",
      "|Electronics|0.24285714285714285|\n",
      "|Clothing   |0.24400000000000005|\n",
      "|Beauty     |0.2285             |\n",
      "+-----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing batch 2\n",
      "+-----------+-------------------+\n",
      "|category   |avg_discount       |\n",
      "+-----------+-------------------+\n",
      "|Home       |0.2555555555555556 |\n",
      "|Sports     |0.21875            |\n",
      "|Electronics|0.24285714285714285|\n",
      "|Clothing   |0.2554545454545455 |\n",
      "|Beauty     |0.2285             |\n",
      "+-----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing batch 3\n",
      "Processing batch 0\n",
      "+-------+------------------+------------------+-----------+\n",
      "|user_id|user_name         |user_location     |event_count|\n",
      "+-------+------------------+------------------+-----------+\n",
      "|484    |Lisa Williams     |Lake Robert       |2          |\n",
      "|246    |Amy Cooper        |Connieberg        |2          |\n",
      "|267    |Doris Stewart     |Lake Kathleenmouth|2          |\n",
      "|358    |Jeffrey Howell    |Perezmouth        |2          |\n",
      "|565    |Christopher Acosta|Shellystad        |2          |\n",
      "+-------+------------------+------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing batch 1\n",
      "+-------+------------------+------------------+-----------+\n",
      "|user_id|user_name         |user_location     |event_count|\n",
      "+-------+------------------+------------------+-----------+\n",
      "|484    |Lisa Williams     |Lake Robert       |2          |\n",
      "|246    |Amy Cooper        |Connieberg        |2          |\n",
      "|267    |Doris Stewart     |Lake Kathleenmouth|2          |\n",
      "|358    |Jeffrey Howell    |Perezmouth        |2          |\n",
      "|565    |Christopher Acosta|Shellystad        |2          |\n",
      "+-------+------------------+------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing batch 2\n",
      "+-------+------------------+------------------+-----------+\n",
      "|user_id|user_name         |user_location     |event_count|\n",
      "+-------+------------------+------------------+-----------+\n",
      "|484    |Lisa Williams     |Lake Robert       |2          |\n",
      "|246    |Amy Cooper        |Connieberg        |2          |\n",
      "|267    |Doris Stewart     |Lake Kathleenmouth|2          |\n",
      "|358    |Jeffrey Howell    |Perezmouth        |2          |\n",
      "|565    |Christopher Acosta|Shellystad        |2          |\n",
      "+-------+------------------+------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing batch 3\n",
      "+-------+------------------+------------------+-----------+\n",
      "|user_id|user_name         |user_location     |event_count|\n",
      "+-------+------------------+------------------+-----------+\n",
      "|484    |Lisa Williams     |Lake Robert       |2          |\n",
      "|246    |Amy Cooper        |Connieberg        |2          |\n",
      "|267    |Doris Stewart     |Lake Kathleenmouth|2          |\n",
      "|358    |Jeffrey Howell    |Perezmouth        |2          |\n",
      "|565    |Christopher Acosta|Shellystad        |2          |\n",
      "+-------+------------------+------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def process_batch(batch_df, batch_id):\n",
    "    print(f\"Processing batch {batch_id}\")\n",
    "    batch_df.show(5, truncate=False)\n",
    "\n",
    "average_discount_by_category_query = average_discount_by_category \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .trigger(processingTime=\"5 seconds\") \\\n",
    "    .foreachBatch(process_batch) \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "494e7c2f-b308-4e67-8b5b-17df8584e0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_discount_by_category_query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08af808-1fa3-40e9-8a41-c25d26642f9e",
   "metadata": {},
   "source": [
    "Most Active Users (by Event Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a15ab42c-b0af-4342-8b0d-bf7cdf1dbacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_activity = enriched_df.groupBy(\"user_id\", \"user_name\", \"user_location\") \\\n",
    "    .agg(count(\"event_type\").alias(\"event_count\")) \\\n",
    "    .orderBy(desc(\"event_count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3936e5ec-8d69-4768-8e56-bdccd72b45e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch_df, batch_id):\n",
    "    print(f\"Processing batch {batch_id}\")\n",
    "    batch_df.show(5, truncate=False)\n",
    "\n",
    "user_activity_query = user_activity \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .trigger(processingTime=\"5 seconds\") \\\n",
    "    .foreachBatch(process_batch) \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5f883e3-4e45-474d-8cbb-c992931a845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_activity_query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2764a274-7d7f-4574-ba58-30a0bc0448d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0x2cb93fe47a0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of writing total revenue by category to a Parquet file\n",
    "total_revenue_by_category.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"parquet\") \\\n",
    "    .option(\"path\", \"C:/kafka-poc/output/revenue_by_category\") \\\n",
    "    .option(\"checkpointLocation\", \"C:/kafka-poc/checkpoint/revenue_by_category\") \\\n",
    "    .start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e42f40be-6e95-4723-aeae-096860e0ef73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are active streaming queries:\n",
      "Query ID: fa1ea7dd-1def-430a-9d00-1709378535a5, Status: {'message': 'Getting offsets from KafkaV2[Subscribe[realtimedashboard]]', 'isDataAvailable': False, 'isTriggerActive': True}\n"
     ]
    }
   ],
   "source": [
    "# Get all active streaming queries\n",
    "active_queries = spark.streams.active\n",
    "\n",
    "# Check if there are any active streaming queries\n",
    "if len(active_queries) > 0:\n",
    "    print(\"There are active streaming queries:\")\n",
    "    for query in active_queries:\n",
    "        print(f\"Query ID: {query.id}, Status: {query.status}\")\n",
    "else:\n",
    "    print(\"No active streaming queries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b678f16-99d6-45e7-bf23-e31d97bc7e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping query with ID: fa1ea7dd-1def-430a-9d00-1709378535a5\n"
     ]
    }
   ],
   "source": [
    "for query in spark.streams.active:\n",
    "    print(f\"Stopping query with ID: {query.id}\")\n",
    "    query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6bc2a44-5782-4e17-81ed-964b95588027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No active streaming queries.\n"
     ]
    }
   ],
   "source": [
    "# Get all active streaming queries\n",
    "active_queries = spark.streams.active\n",
    "\n",
    "# Check if there are any active streaming queries\n",
    "if len(active_queries) > 0:\n",
    "    print(\"There are active streaming queries:\")\n",
    "    for query in active_queries:\n",
    "        print(f\"Query ID: {query.id}, Status: {query.status}\")\n",
    "else:\n",
    "    print(\"No active streaming queries.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark Kernel",
   "language": "python",
   "name": "pyspark_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
